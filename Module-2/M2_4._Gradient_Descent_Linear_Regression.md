# ðŸ“˜ Figuring Out Parameters Using Gradient Descent

---

## 1. Goal

We want to find values of parameters ($\theta_0, \theta_1, ...$) such that the **cost function $J(\theta)$** is minimized.

* Cost function $J(\theta)$ = measures how bad our predictions are.
* Objective:

  $$
  \min_{\theta} J(\theta)
  $$

---

## 2. How Gradient Descent Works

### Algorithm (high-level steps):

1. Start with random values for parameters ($\theta_0, \theta_1$).
2. Compute cost $J(\theta)$.
3. Compute gradient (derivative) â†’ tells us **slope of cost function**.
4. Update parameters in the **opposite direction** of the slope.
5. Repeat until convergence (when cost stops decreasing).

---

## 3. The Update Formula

For each parameter $\theta_j$:

$$
\theta_j := \theta_j - \alpha \frac{\partial}{\partial \theta_j} J(\theta)
$$

* $\alpha$ = learning rate (step size).
* $\frac{\partial}{\partial \theta_j} J(\theta)$ = partial derivative of cost function wrt parameter.

ðŸ‘‰ Meaning:

* If slope is **positive** â†’ decrease $\theta_j$.
* If slope is **negative** â†’ increase $\theta_j$.
* Keep adjusting until slope â‰ˆ 0 (minimum point).

---

## 4. Intuition of Derivative

* Derivative = slope of the curve at a point.
* If slope is steep â†’ we are far from minimum, take big steps.
* If slope is flat â†’ we are near minimum, steps become smaller.

Diagram (U-shaped cost function with slope arrows):

```
      Cost J(Î¸)
        |
        |        â€¢ (start, random Î¸)
        |       â†™
        |     â†™
        |   â†™
        | â€¢ (minima, best Î¸)
        +------------------> Î¸
```

---

## 5. Local vs Global Minima

* **Global minimum:** lowest point in entire cost curve (ideal solution).
* **Local minimum:** a dip that is lower than nearby points but not the lowest overall.

### Important Note (Linear Regression case):

* Since cost function in linear regression is **convex (U-shaped bowl)**,

  * There is **only one minimum** (global).
  * So gradient descent **always finds the global minimum**, no worry of local minima.

ðŸ‘‰ Local minima problem happens in **non-linear models (like neural networks)**, not in basic linear regression.

---

## 6. Effect of Learning Rate ($\alpha$)

* $\alpha$ controls how big the steps are.

Diagram intuition:

```
Good LR (Î± moderate):
Start â†’ step â†’ step â†’ min

Too small LR (Î± tiny):
Start â†’ small step â†’ very slow â†’ min

Too large LR (Î± huge):
Start â†’ overshoot â†’ bounce â†’ may never converge
```

* **Small $\alpha$:** converges slowly.
* **Large $\alpha$:** may overshoot and diverge.
* **Right $\alpha$:** balances speed and stability.

---

## 7. Full Gradient Descent Algorithm (Linear Regression Case)

1. Initialize parameters $\theta_0, \theta_1, ..., \theta_n$ randomly (often zeros).

2. Repeat until convergence:

   $$
   \theta_j := \theta_j - \alpha \frac{1}{m} \sum_{i=1}^{m}\Big(h(x^{(i)}) - y^{(i)}\Big)x_j^{(i)}
   $$

   where:

   $$
   h(x^{(i)}) = \theta_0 + \theta_1 x_1^{(i)} + \ldots + \theta_n x_n^{(i)}
   $$

   $$
   m = \text{number of training examples}
   $$

3. Stop when $J(\theta)$ stops decreasing significantly.

---

## 8. Visualization of Gradient Descent (Cost Contour)

For 2 parameters ($\theta_0, \theta_1$):

```
   Contour Map of J(Î¸0, Î¸1)
   -------------------------
        âˆ˜   âˆ˜   âˆ˜   âˆ˜    (high cost)
          âˆ˜       âˆ˜
             âˆ˜  (global min)
```

* Each circle = equal cost.
* Algorithm starts at a random point (outer circle).
* Moves step by step towards the center (minimum).

---

## 9. Key Points to Memorize

* Gradient Descent = iterative optimization to minimize cost.
* Update rule:

  $$
  \theta_j := \theta_j - \alpha \frac{\partial}{\partial \theta_j} J(\theta)
  $$
* Linear regression cost = convex â†’ only **global minimum**.
* Learning rate ($\alpha$) must be chosen carefully.
* Gradient = slope; moving opposite slope leads to minima.

---
