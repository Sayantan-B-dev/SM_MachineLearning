# ğŸŒ Multivariate Linear Regression

### ğŸ”¹ Hypothesis function

For **one variable** (simple regression):

$$
h_\theta(x) = \theta_0 + \theta_1 x
$$

For **multiple variables** ($n$ features):

$$
h_\theta(x) = \theta_0 + \theta_1 x_1 + \theta_2 x_2 + \cdots + \theta_n x_n
$$

To make math elegant, we define:

* $x_0 = 1$ (a dummy feature for bias/intercept)
* Feature vector:

$$
x =
\begin{bmatrix}
x_0 \\
x_1 \\
x_2 \\
\vdots \\
x_n
\end{bmatrix}
$$

* Parameter vector:

$$
\theta =
\begin{bmatrix}
\theta_0 \\
\theta_1 \\
\theta_2 \\
\vdots \\
\theta_n
\end{bmatrix}
$$

Then:

$$
h_\theta(x) = \theta^T x
$$

which is **vectorized hypothesis** (very common in ML).

---

# ğŸ§® Cost Function (MSE)

The cost is still **Mean Squared Error (MSE)**:

$$
J(\theta) = \frac{1}{2m} \sum_{i=1}^{m} \Big( h_\theta(x^{(i)}) - y^{(i)} \Big)^2
$$

* $m$ = number of training examples
* $x^{(i)}$ = feature vector of the $i$-th example
* $y^{(i)}$ = true output

The goal: **minimize $J(\theta)$ by adjusting all $\theta_j$.**

---

# ğŸŒ€ Gradient Descent Update Rule

For each parameter $\theta_j$:

$$
\theta_j := \theta_j - \alpha \frac{\partial}{\partial \theta_j} J(\theta)
$$

ğŸ‘‰ Derivative result:

$$
\theta_j := \theta_j - \alpha \cdot \frac{1}{m} \sum_{i=1}^{m} \Big( h_\theta(x^{(i)}) - y^{(i)} \Big) x_j^{(i)}
$$

So:

* For **bias term** ($\theta_0$):

$$
\theta_0 := \theta_0 - \alpha \cdot \frac{1}{m} \sum_{i=1}^{m} \Big( h_\theta(x^{(i)}) - y^{(i)} \Big) \cdot 1
$$

* For **feature weights** ($\theta_1, \theta_2, ...$):

$$
\theta_j := \theta_j - \alpha \cdot \frac{1}{m} \sum_{i=1}^{m} \Big( h_\theta(x^{(i)}) - y^{(i)} \Big) x_j^{(i)}
$$

---

# ğŸ“Š Why Update All Parameters Simultaneously?

Suppose you update **$\theta_0$** first, then use the updated value while computing **$\theta_1$**.

â¡ï¸ Problem: The updates become **dependent**, and $\theta_1$ is based on a partially changed cost function.
â¡ï¸ This disturbs the path to the **true gradient direction** and can cause oscillation or divergence.

âœ… Correct method: Compute all updates **in parallel** using the *old values of all $\theta_j$*. After computing the updates, apply them simultaneously.

This ensures weâ€™re **always moving in the correct descent direction**.

---

# ğŸŒ„ Local vs Global Minima in Multivariate

In **linear regression**, the cost function $J(\theta)$ is **convex** (a "bowl" shape in higher dimensions).

* Convex â‡’ only **one global minima**, no local minima traps.
* This is why linear regression is easier compared to neural networks.

**3D Bowl-shaped cost function for 2 parameters:**

```
       J(Î¸)
        |
        |        .
        |      .   .
        |   .        .
        |.______________  Î¸1
       /
      /
     Î¸0
```

The **bottom of the bowl** = global minima.

---

# ğŸ–¼ï¸ Clean Diagram: Vectorized Gradient Descent

```
x = [x0, x1, x2, ..., xn]áµ€   (feature vector)
Î¸ = [Î¸0, Î¸1, Î¸2, ..., Î¸n]áµ€   (parameter vector)

Hypothesis:
hÎ¸(x) = Î¸áµ€x

Gradient descent update (vectorized):
Î¸ := Î¸ - Î± * (1/m) * Xáµ€ (XÎ¸ - y)
```

Where:

* $X$ = design matrix (m Ã— n) of features
* $y$ = output vector
* $XÎ¸ - y$ = vector of residuals

---

âœ… Summary (easy to memorize):

* Hypothesis: $h_\theta(x) = \theta^T x$
* Cost: $J(\theta) = \frac{1}{2m}\sum (h_\theta(x)-y)^2$
* Update: $\theta_j := \theta_j - \alpha \frac{1}{m}\sum (h_\theta(x)-y)x_j$
* Update all $\theta$ simultaneously using the same cost
* Cost is convex (guaranteed global minima, no traps)

---

# All together:
# ğŸ“˜ Linear Regression â€” Full Study Notes

---

## 1. ğŸŒ What is Linear Regression?

Linear regression is a **supervised learning algorithm** used for predicting a continuous output (numeric value) from one or more input features.

* Goal: Find a **linear relationship** between input(s) and output.
* Applications:

  * Predicting house prices ğŸ 
  * Salary prediction ğŸ’°
  * Forecasting demand ğŸ“ˆ
  * Medical predictions (e.g., blood pressure vs. age, weight)

---

## 2. âœï¸ Simple Linear Regression (One Feature)

We want to model:

$$
y \approx h_\theta(x) = \theta_0 + \theta_1 x
$$

* $x$ = input feature (independent variable)
* $y$ = target (dependent variable)
* $\theta_0$ = intercept (bias)
* $\theta_1$ = slope (weight for feature)

ğŸ‘‰ Itâ€™s like fitting a **straight line** through data points.

---

### ğŸ”¹ Geometric Meaning of Parameters

* **Intercept ($\theta_0$)** â†’ vertical shift (moves the line up or down).
* **Slope ($\theta_1$)** â†’ tilt/steepness of the line (how fast y changes with x).

ğŸ–¼ï¸ Diagram (line fitting idea):

```
y
|
|       *
|   *           *
|       *   *
|______________________ x
       best-fit line
```

---

## 3. ğŸ§® Cost Function (How good is a line?)

We measure the **error** between predictions and actual values.

* Prediction:

$$
h_\theta(x^{(i)}) = \theta_0 + \theta_1 x^{(i)}
$$

* Error for example $i$:

$$
error^{(i)} = h_\theta(x^{(i)}) - y^{(i)}
$$

* Squared error (avoid negatives):

$$
(error^{(i)})^2 = (h_\theta(x^{(i)}) - y^{(i)})^2
$$

* **Cost function (Mean Squared Error):**

$$
J(\theta_0, \theta_1) = \frac{1}{2m} \sum_{i=1}^{m} (h_\theta(x^{(i)}) - y^{(i)})^2
$$

ğŸ–¼ï¸ Cost function surface (convex bowl):

```
   J(Î¸0,Î¸1)
      |
      |        .
      |     .     .
      |   .         .
      |.______________ Î¸1
     /
    /
   Î¸0
```

* **Why squared error?**

  * Always positive
  * Penalizes large errors more
  * Smooth, differentiable function (great for calculus optimization)

---

## 4. ğŸŒ€ Gradient Descent (Finding the Best Line)

We want values of $\theta_0, \theta_1$ that minimize $J(\theta_0,\theta_1)$.
Instead of guessing, we use **gradient descent**.

### ğŸ”¹ Steps:

1. Initialize $\theta_0, \theta_1$ randomly.
2. Repeat until convergence:

   $$
   \theta_j := \theta_j - \alpha \frac{\partial}{\partial \theta_j} J(\theta_0,\theta_1)
   $$

   where:

   * $\alpha$ = learning rate (step size)
   * $\frac{\partial}{\partial \theta_j} J$ = slope/derivative w\.r.t parameter

ğŸ‘‰ For linear regression:

* Update for intercept:

$$
\theta_0 := \theta_0 - \alpha \frac{1}{m}\sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)})
$$

* Update for slope:

$$
\theta_1 := \theta_1 - \alpha \frac{1}{m}\sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)})x^{(i)}
$$

---

### ğŸ”¹ Intuition of Gradient Descent

* Derivative = slope of tangent (direction of steepest increase).
* Negative derivative = move opposite to slope to **descend**.
* $\alpha$ (learning rate) controls step size:

  * Too small â†’ very slow
  * Too big â†’ may overshoot or diverge
  * Just right â†’ smooth convergence

ğŸ–¼ï¸ Graph of cost vs parameter:

```
J(Î¸)
|
|        *
|     *       *
|   *
| *        minima (best Î¸)
|___________________ Î¸
```

---

## 5. ğŸ”¢ Multivariate Linear Regression

Now, suppose we have **n features**.

$$
h_\theta(x) = \theta_0 + \theta_1x_1 + \theta_2x_2 + \cdots + \theta_nx_n
$$

### ğŸ”¹ Vectorized Form

Define:

$$
x =
\begin{bmatrix}
x_0 \\
x_1 \\
x_2 \\
\vdots \\
x_n
\end{bmatrix}, \quad
\theta =
\begin{bmatrix}
\theta_0 \\
\theta_1 \\
\theta_2 \\
\vdots \\
\theta_n
\end{bmatrix}
$$

Then:

$$
h_\theta(x) = \theta^T x
$$

### ğŸ”¹ Cost Function

$$
J(\theta) = \frac{1}{2m}\sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)})^2
$$

### ğŸ”¹ Gradient Descent (vectorized form)

$$
\theta := \theta - \alpha \cdot \frac{1}{m} X^T (X\theta - y)
$$

Where:

* $X$ = matrix of features (m Ã— n)
* $y$ = vector of outputs (m Ã— 1)
* $X\theta - y$ = vector of residuals

---

## 6. ğŸŒ„ Why All Parameters Update Simultaneously?

* If we update $\theta_0$ first and use that new value when updating $\theta_1$, updates become inconsistent.
* Correct way: compute all gradients **using old parameters** â†’ update simultaneously.
* This ensures the step is taken in the **true gradient direction**.

---

## 7. âš¡ Local vs Global Minima

* In linear regression: **Cost function is convex** (parabola/bowl).
* There is **only one global minimum**.
* Gradient descent always converges to it (if $\alpha$ is chosen properly).

---

## 8. ğŸ§© Practical Issues

* **Feature scaling / normalization**

  * Different scales (e.g., age vs income) can slow down convergence.
  * Normalize features to $[0,1]$ or mean 0, std 1.

* **Learning rate tuning**

  * Small enough to converge, large enough to be efficient.
  * Sometimes need trial & error or adaptive methods.

* **Polynomial regression**

  * Linear regression can be extended by adding powers of features ($x^2, x^3$) for nonlinear patterns.

---

## 9. âœ… Recap (easy to memorize)

* Hypothesis: $h_\theta(x) = \theta^T x$
* Cost function: $J(\theta) = \frac{1}{2m}\sum (h_\theta(x)-y)^2$
* Gradient descent update:

$$
\theta_j := \theta_j - \alpha \frac{1}{m}\sum (h_\theta(x)-y)x_j
$$

* Vectorized update:

$$
\theta := \theta - \alpha \cdot \frac{1}{m} X^T (X\theta - y)
$$

* Convex cost â‡’ guaranteed global minimum.

---