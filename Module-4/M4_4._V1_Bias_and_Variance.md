# Bias

---

## **1. Core Idea**

Bias measures the **average error between model predictions and true values**.
It reflects how much the model **assumptions simplify the real-world data**.

$$
\text{Bias} = \text{Expected}[\hat{f}(x)] - f(x)
$$

Where:

* ( \hat{f}(x) ) = model prediction
* ( f(x) ) = true underlying function

---

## **2. Interpretation**

| Bias Level    | Training Error | Model Behavior                              |
| ------------- | -------------- | ------------------------------------------- |
| **High Bias** | High           | Model is too simple → **underfitting**      |
| **Low Bias**  | Low            | Model captures patterns well → **good fit** |

* **High bias → underfit** → fails on **training and test data**
* **Low bias → better prediction** → captures training patterns

---

## **3. Visual Intuition**

```
High Bias (Underfitting)
True function:      *****
Model prediction:   -----
Error: large difference

Low Bias (Good Fit)
True function:      *****
Model prediction:   ***** 
Error: small difference
```

---

## **4. Key Notes**

* Bias reflects **model assumptions** (simplicity vs complexity)
* High bias → model too rigid, ignores data patterns
* Bias is **one side of the bias-variance tradeoff**

---

## **5. Memory Hook**

* **“High bias = too simple → misses patterns”**
* **“Low bias = captures true patterns → good accuracy”**

---

# Variance

---

## **1. Core Idea**

Variance measures how much the model's predictions **change across different training datasets**.
It reflects the model’s **sensitivity to small fluctuations or noise** in the data.

$$
\text{Variance} = \mathbb{E}\Big[\big(\hat{f}(x) - \mathbb{E}[\hat{f}(x)]\big)^2\Big]
$$





Where:

* $\hat{f}(x)$ = model prediction  
* $\mathbb{E}[\hat{f}(x)]$ = expected prediction across datasets

---

## **2. Interpretation**

| Variance Level    | Test Error | Model Behavior                                            |
| ----------------- | ---------- | --------------------------------------------------------- |
| **High Variance** | High       | Model overfits → sensitive to noise → poor generalization |
| **Low Variance**  | Low        | Model predictions stable → generalizes well               |

* **High variance → overfit** → good on training data but poor on unseen data
* **Low variance → model stable** → consistent predictions

---

## **3. Visual Intuition**

```
High Variance (Overfitting)
Training data:      *
Model prediction:  *   *   *   *  (changes a lot with each dataset)
Error on test:      large

Low Variance (Good Generalization)
Training data:      *
Model prediction:    *
Error on test:      small
```

---

## **4. Key Notes**

* Variance reflects **model flexibility**
* High variance → model memorizes noise, sensitive to training data
* Variance is **other side of the bias-variance tradeoff**

---

## **5. Memory Hook**

* **“High variance = too flexible → memorizes noise”**
* **“Low variance = stable predictions → generalizes well”**

---

