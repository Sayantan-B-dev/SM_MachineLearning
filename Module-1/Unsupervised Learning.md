## **Unsupervised Learning**

Unsupervised learning is a type of machine learning where **we do not have labeled data**.
The algorithm tries to **find patterns, structure, or relationships** within the dataset **without knowing the output beforehand**.

---

### **Key Characteristics**

* **No labels** â†’ No predefined "right answer"
* **No feedback** â†’ The model is not corrected during training
* **Goal** â†’ Discover hidden structure (clusters, patterns, lower-dimensional representations)

---

### **Major Types**

### **1. Clustering**

The algorithm groups data points based on similarity.
Objective: Points in the same group are more similar to each other than points in other groups.

**Example Algorithms:**

* **K-Means Clustering** â†’ Partitions data into *k* groups
* **Hierarchical Clustering** â†’ Builds a tree of clusters
* **DBSCAN** â†’ Finds dense regions & treats outliers as noise

```md
# Resembling an Image (Clusters)
â¬¤ â¬¤ â¬¤        â¬¤ â¬¤        â¬¤â¬¤â¬¤â¬¤â¬¤
â¬¤ â¬¤           â¬¤â¬¤â¬¤       â¬¤
â¬¤â¬¤â¬¤           â¬¤â¬¤â¬¤â¬¤â¬¤    â¬¤â¬¤â¬¤â¬¤
(Imagine: Left cluster, middle cluster, right cluster)
```

---

### **2. Dimensionality Reduction**

Reduces the number of features/variables while keeping as much information as possible.

**Why we do this:**

* Make data easier to visualize (e.g., project 3D â†’ 2D)
* Reduce computational cost
* Remove noise & redundant features

**Common Techniques:**

* **PCA (Principal Component Analysis)** â†’ Finds directions of maximum variance
* **t-SNE, UMAP** â†’ Better for visualization of complex data

```md
# Resembling an Image (Dimensionality Reduction)
3D Cube â†’ 2D Plane â†’ Line

[â– â– â– ]  â†’  [â– â– ]  â†’  [â– ]
(Imagine: Reducing number of dimensions step by step)
```

---

### **Applications**

#### **1. Anomaly Detection**

* Finds data points that do not belong to any cluster (outliers)
* **Use Cases:**

  * Credit card fraud detection
  * Network intrusion detection
  * Machine failure prediction

```md
# Resembling an Image (Anomaly Detection)
â¬¤â¬¤â¬¤â¬¤â¬¤â¬¤â¬¤â¬¤â¬¤      â¬¤ (â† Anomaly)
â¬¤â¬¤â¬¤â¬¤â¬¤â¬¤â¬¤â¬¤â¬¤
```

---

#### **2. Zone/Community Detection (Clustering Example)**

* **Use Case:** Dividing a city map into zones based on population density
* Each point (house, shop) looks for its neighbors â†’ forms a community

```md
# Resembling an Image (Zones/Regions)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ (Decision Boundary)
Cluster A       | Cluster B
â¬¤â¬¤â¬¤â¬¤â¬¤â¬¤â¬¤â¬¤â¬¤ | â¬¤â¬¤â¬¤â¬¤â¬¤â¬¤â¬¤â¬¤â¬¤
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ (Decision Boundary)
Cluster C
â¬¤â¬¤â¬¤â¬¤â¬¤â¬¤â¬¤â¬¤â¬¤â¬¤â¬¤â¬¤
```

---

### **KNN (K-Nearest Neighbors) Note**

Even though **KNN** is mostly used for classification, you can think of it as:

* Each new point checks **its K nearest neighbors**
* Decides which cluster/class it should belong to based on majority vote

```md
# Resembling an Image (KNN)
â¬¤â¬¤â¬¤(Neighbor 1)â¬¤â¬¤
   â¬¤ (New Point â†’ Joins cluster of nearest neighbors)
```

---

## **ğŸ“Œ K-Means Clustering â€” Algorithm**

```md
# K-Means Clustering Pseudo-Code

1. Choose number of clusters K
2. Randomly select K points as initial centroids
3. Repeat until convergence:
   a) Assign each data point to the nearest centroid
   b) Update centroids (average of all points in cluster)
4. When centroids stop changing significantly â†’ DONE
```

---

### **Flowchart-like Representation**

```md
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚  Choose K Clusters   â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚  Pick K Centroids    â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚ Assign Points to     â”‚
          â”‚ Nearest Centroid     â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚ Recompute Centroids  â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚  Centroids Change?   â”‚
          â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚Yes   â”‚No
                â”‚      â”‚
                â†“      â†“
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚ Repeat Assignment    â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚ Final Clusters Formedâ”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## **ğŸ“Œ Anomaly Detection â€” Algorithm**

```md
# Anomaly Detection (Unsupervised) Pseudo-Code

1. Collect normal data points (no anomalies)
2. Learn distribution/pattern of normal data
3. For a new data point:
   a) Calculate probability of belonging to normal distribution
   b) If probability < threshold â†’ FLAG as anomaly
   c) Else â†’ Mark as normal
```

---

### **Flowchart-like Representation**

```md
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚ Train on Normal Data â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚ New Data Point Comes â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚ Compute Probability  â”‚
          â”‚ (Belongs to Normal?) â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚ Probability < Thresh?â”‚
          â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚Yes   â”‚No
                â”‚      â”‚
                â†“      â†“
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚  FLAG AS ANOMALY     â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ NORMAL
```

---

These flowcharts look quite nice in Markdown because they give a **visual hierarchy** of steps â€” easy for internship notes and interviews.

---